---
author: bydiao
comments: true
date: 2017-05-01
layout: post
title: 时序学习 2
mathjax: true
categories: [Machine Learning]
tags: [Time Learning]
---

## Chapter 3  Regression Analysis and Forecasting

solving problem like
an outcome or response
one or more predictor or regressor

#### 3.1Introduction

Simple linear Regression Model

$y=\beta_0 + \beta_1 x + \epsilon$

$y=\beta_0 + \beta_1 x + \beta_2 x^2 + \epsilon$

以上都是线性模型，线性指的是系数为线性

两种线性回归模型

Cross-Section data  预测价格
Times Series data   预测时序趋势

## 3.2 最小二乘法预测回归模型

1. cross-section data Regression

$L=\sum^n_{i=1}\epsilon_i^2=\sum^n_{i=1}(y_i-\beta_0-\beta_1x_{i1}-\beta_2x_{i2}-...-\beta_kx_{ik})^2$
$=\sum^n_{i=1}(y_i-\beta_0-\sum^k_{j=1}\beta_j x_{ij})^2$

求最小值，即让L对所有$\beta$的偏导数为0，得到一系列的方程组，接这个方程组，得到的$\beta$向量

用矩阵和向量来表示

即为
$\frac{\partial L}{\partial \beta}|_{\beta ^ *} = -2 X' y + 2(X'X)\beta^*=0$

$\beta^*=(X'X)^{-1}X'y$

最终 error为
$e=y-y^*=y-X\beta^*$

Example 3.2 Trend Adjustment
通过递推公式来做参数预测

## 3.3 Statistical Inference in Linear Regression
验证有效性
该方法在论文中可以有效证明线性模型对预测的有效性
提出了一些有效性验证模型

这部分内容可以提升理论性

## 3.5 Model Adequacy Checking
## 3.6 Variable selection
## 3.7 Generalized and weighted least squares
nonconstant variance
Method 1 Transformation
Mathod 2 weighted Least Square
$L=\sum^n_i \omega_i(y_i-\beta_0-\beta_1x_i)$


## 3.7.2 Estimation of a Variance Equation
1. iteratively reweighted least squares (IRLS)
2. Replicate observations 
3. Nearest neighbors (*Time Sequence Nearest neihgbors*)


## 3.8 Regression Mode for general time series data




